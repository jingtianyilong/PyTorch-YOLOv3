{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "from utils.kittiloader import *\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import NullLocator\n",
    "import time\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "def drawBEV(point_cloud_,color=(0,1,0)):\n",
    "    ''' Draw a bird eye view using matplotlib\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    f = plt.figure(figsize=(18, 14))\n",
    "    ax = f.add_subplot(111)\n",
    "    ax.scatter(point_cloud_[:,1],point_cloud_[:,0],\n",
    "                s=0.1, c=[color]*len(point_cloud_))\n",
    "    ax.set_title('BEV before frustum extraction')\n",
    "    ax.set_ylim(0,15)\n",
    "    ax.set_xlim(-10,10)\n",
    "    ax.set_facecolor((0,0,0))\n",
    "# #     plt.show()\n",
    "    \n",
    "def draw3D(point_cloud_,color=(0,1,0),angle=(60,180)):\n",
    "    f = plt.figure(figsize=(15, 10))\n",
    "    ax = f.add_subplot(111, projection='3d')\n",
    "    ax.set_facecolor((0, 0, 0))\n",
    "    ax.set_xlim3d(-10,20)\n",
    "    ax.set_ylim3d(-10,10)\n",
    "    ax.set_zlim3d(-3,5)\n",
    "    ax.view_init(angle[0],angle[1])\n",
    "    ax.grid(False)\n",
    "    plt.axis('off')\n",
    "    ax.scatter(point_cloud_[:,0],point_cloud_[:,1],point_cloud_[:,2], s=0.1, c=[(0,1,0)]*len(point_cloud_))\n",
    "#     plt.show()\n",
    "\n",
    "axes_limits = [\n",
    "    [0, 10], # X axis range\n",
    "    [-10, 10], # Y axis range\n",
    "    [-3, 10]   # Z axis range\n",
    "]\n",
    "axes_str = ['X', 'Y', 'Z']\n",
    "\n",
    "\n",
    "image_folder = 'examples/'\n",
    "config_path = 'config/v390.cfg'\n",
    "weights_path = 'weights/v390_final.weights'\n",
    "kitti_path = '/home/project/ZijieMA/KITTI/'\n",
    "class_path = 'data/coco.names'\n",
    "conf_thres = 0.5\n",
    "nms_thres = 0.4\n",
    "batch_size = 1\n",
    "n_cpu = 16\n",
    "img_size = 416\n",
    "use_cuda = True\n",
    "CUDA_available = torch.cuda.is_available() and use_cuda\n",
    "\n",
    "detections = torch.tensor([\n",
    "    [  5.0433, 208.0689, 133.5634, 274.0513,   0.9992,   0.9995,   2.0000],\n",
    "         [202.3678, 203.0705, 242.1279, 233.4327,   0.9980,   0.9999,   2.0000],\n",
    "         [118.8502, 203.6419, 208.2199, 263.8680,   0.9891,   0.9758,   2.0000]\n",
    "])\n",
    "if detections[0] is not None:\n",
    "        detections_with_distance = torch.zeros((detections.shape[0],detections.shape[1]+1))\n",
    "        detections_with_distance[:,:-1] = detections\n",
    "        \n",
    "img_id = 8\n",
    "img_path = 'examples/000008.png'\n",
    "img_size_after_resize = img_size\n",
    "lidar_path = '%straining/velodyne/%06d.bin' % (kitti_path, img_id)\n",
    "calib = calibread('%straining/calib/%06d.txt' % (kitti_path, img_id))\n",
    "img = cv2.imread('/home/project/ZijieMA/PyTorch-YOLOv3/examples/%06d.png' % img_id, cv2.IMREAD_UNCHANGED)\n",
    "# img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "img_width_orig = img.shape[1]\n",
    "\n",
    "img_height_orig = img.shape[0]\n",
    "\n",
    "pad_x = max(img_height_orig - img_width_orig, 0) * (img_size_after_resize / max(img_width_orig, img_height_orig))\n",
    "pad_y = max(img_width_orig - img_height_orig, 0) * (img_size_after_resize / max(img_width_orig, img_height_orig))\n",
    "point_cloud = np.fromfile(lidar_path, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "# Image height and width after padding is removed\n",
    "unpad_h = img_size_after_resize - pad_y\n",
    "unpad_w = img_size_after_resize - pad_x\n",
    "# detections with shape: (x1, y1, x2, y2, object_conf, class_score, class_pred)\n",
    "\n",
    "P2 = calib[\"P2\"] # 3x4 matris projection matrix after rectification\n",
    "# （u,v,1） = dot(P2, (x,y,z,1))\n",
    "Height_of_camera = 1.65\n",
    "fu = P2[0][0]  # for horizontal position\n",
    "fv = P2[1][1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for detection in detections_with_distance:\n",
    "    detection = detection.numpy()\n",
    "    point_cloud = np.fromfile(lidar_path, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    # detections with shape: (x1, y1, x2, y2, object_conf, class_score, class_pred)\n",
    "    box_h = ((detection[3] - detection[1]) / unpad_h) * img_height_orig\n",
    "    box_w = ((detection[2] - detection[0]) / unpad_w) * img_width_orig\n",
    "    v_upper = ((detection[1] - pad_y // 2) / unpad_h) * img_height_orig\n",
    "    u_left = ((detection[0] - pad_x // 2) / unpad_w) * img_width_orig\n",
    "    v_bottom = v_upper + box_h\n",
    "    u_right = u_left + box_w\n",
    "    D_rough = Height_of_camera * fv / (v_bottom - img_height_orig/2)\n",
    "    if D_rough > 0:\n",
    "        # remove points that are located behind the camera:\n",
    "        point_cloud = point_cloud[point_cloud[:, 0] > (D_rough - 3), :]\n",
    "        # remove points that are located too far away from the camera:\n",
    "        point_cloud = point_cloud[point_cloud[:, 0] < min(80, D_rough + 3), :]\n",
    "        point_cloud = point_cloud[point_cloud[:,2] > -1.5,:]\n",
    "        point_cloud = point_cloud[point_cloud[:,2] < -1,:]\n",
    "        \n",
    "        ########################################################################\n",
    "        # point_cloud               n x 4   original xyzr value before cali in velo coordinate\n",
    "        # point_cloud_xyz           n x 3   xyz value before cali in velo coordinate\n",
    "        # point_cloud_xyz_hom       n x 4   xyz1 in velo coordinate\n",
    "        # point_cloud_xyz_camera    n x 4   xyz1 in camera coordinate\n",
    "        # point_cloud_camera        n x 4   xyzr in camera coordinate\n",
    "        # img_points_hom            n x 3   uv_\n",
    "        # img_points                n x 2   UV\n",
    "        ########################################################################\n",
    "        \n",
    "        R0_rect = np.eye(4)\n",
    "        R0_rect[0:3, 0:3] = calib[\"R0_rect\"] # 3x3 -> 4x4 up left corner\n",
    "        Tr_velo_to_cam = np.eye(4)\n",
    "        Tr_velo_to_cam[0:3, :] = calib[\"Tr_velo_to_cam\"] # 3x4 -> 4x4 up left corner\n",
    "\n",
    "        # point_cloud_xyz = point_cloud[:, 0:3] # num_point x 3 (x,y,z,reflectance) reflectance don't need\n",
    "        point_cloud_xyz_hom = np.ones((point_cloud.shape[0], 4))\n",
    "        point_cloud_xyz_hom[:, 0:3] = point_cloud[:, 0:3] # (point_cloud_xyz_hom has shape (num_points, 4))\n",
    "        # the 4th column are all 1\n",
    "\n",
    "        # project the points onto the image plane (homogeneous coords):\n",
    "        # (U,V,_) = P2 * R0_rect * Tr_velo_to_cam * point_cloud_xyz_hom\n",
    "        # normalize: (U,V,1)\n",
    "        img_points_hom = np.dot(P2, np.dot(R0_rect, np.dot(Tr_velo_to_cam, point_cloud_xyz_hom.T))).T # (point_cloud_xyz_hom.T has shape (4, num_points))\n",
    "        img_points = np.zeros((img_points_hom.shape[0], 2))\n",
    "        img_points[:, 0] = img_points_hom[:, 0]/img_points_hom[:, 2]\n",
    "        img_points[:, 1] = img_points_hom[:, 1]/img_points_hom[:, 2]\n",
    "\n",
    "        row_mask = np.logical_and(\n",
    "                        np.logical_and(img_points[:, 0] >= u_left,\n",
    "                                       img_points[:, 0] <= u_right),\n",
    "                        np.logical_and(img_points[:, 1] >= v_upper,\n",
    "                                       img_points[:, 1] <= v_bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_mask = point_cloud[row_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def ransac_with_bbox(point_cloud_with_mask,)\n",
    "type(point_cloud_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_with_bbox(point_cloud_with_mask,n_sample,category):\n",
    "    \"\"\"running ransac to return edges for objects\n",
    "\n",
    "    Parameters:\n",
    "    point_cloud_with_mask (numpy.ndarray): Description of arg1\n",
    "\n",
    "    Returns:\n",
    "    int:Returning value\n",
    "\n",
    "   \"\"\"\n",
    "    if category = 2 or 5 or 7:\n",
    "    elif category = 0:\n",
    "    elif category = 1 or 3:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_yolo2",
   "language": "python",
   "name": "pytorch_yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
